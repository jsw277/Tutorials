{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "In this tutorial we will go through a step-by-step process of constructing the Naive Bayes Classifier. Its roots are located in the definition of conditional probability and even though it uses a naive assumption it seems to be working extremely good, especially in the case of spam filtering. Starting from the definition of conditional probability we will make a stop at Bayes rule and then we will construct the classifier. At the end of this tutorial we will move from theory to application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "Consider the following situation. You are a professional boxer and you are given a choice whether you would like to participate in a fight with some opponent. Assuming that you can measure the utility of the fighting experience (after the fight) and given the fact that you will participate in the fight only if that utility is above some threshold, you can use your experience from previous matches to make your decision. To help you decision making you use the prior to the fight knowledge of the amount of money you will take and the winning record of your opponent. It seems reasonable that a challenging match with a good compensation usually provides more utility than a fight with a unworthy opponent and money that will barely cover your new teeth.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "### Bayes Rule\n",
    "Let's start by writing down the definition of _conditional probability_:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(A \\cap B)}{P(B)}\\tag{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above expression gives us the probability that the event A will happen given the fact that we have knowledge that the event B has already happened. Using this definition twice we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A \\cap B)=P(A|B)P(B)\\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A \\cap B)=P(B|A)P(A)\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to equations (1) and (2) the joint probability can be expressed either by using the conditional P(A|B) or P(B|A) and thus we can plug the result of the second equation to the original definition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is the famous Bayes rule. We can rewrite it in terms of the specific problem and see how we can take advantage of it. We could set as event A the case of high utility and as B the money and record variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility|money,record)=\\frac{P(money,record|high\\,utility)P(high\\,utility)}{P(money,record)}\\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So what is Bayes rule all about? Assume that the only knowledge you had was you record of past utility experiences from every fight. How would you decide whether you would like an additional fight or not? Well, you could calculate the ratio of the high utility fights to the total number of fights:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility)=\\frac{number\\,of\\,high\\,utility\\,fights}{number\\,of\\,total\\,fights}\\tag{5}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This the _marginal probability_ and it measures how likely is a high utility fight to happen, taking nothing else into account. It's also known as _prior probability_ since it is the probability of the event before realizing any other useful factors. What Bayes rule actually does is to connect the prior probability with the likelihood and the posterior probability of a good fight where by _posterior probability_ we mean the probability of a good fight after we have realized some important indicators like money and opponent ranking. The conditional probability **P(high utility | money,record)** is the posterior probability. So a reasonable way to make the fight/no fight decision could be the following:\n",
    "* Compute the posterior probability of a **good fight** using the knowledge of money and opponent record\n",
    "* Compute the posterior probability of a **bad fight** using the knowledge of money and opponent record\n",
    "* Choose to fight only if the probability of having a good fight is bigger than the probability of a bad one, taking the money and opponent record features into consideration.\n",
    "\n",
    "We can express it in a mathematical way as well (using the definition of conditional probability): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility|money,record) \\geq P(low\\,utility|money,record) \\implies $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{P(money,record|high\\,utility)P(high\\,utility)}{P(money,record)} \\geq \\frac{P(money,record|low\\,utility)P(low\\,utility)}{P(money,record)}\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can erase the denominator since it is nonzero. All that is left is to compute the likelihood and the prior. Usually we may use more than just two features for our decision making. For example in this problem we could use our personal winning record as well and various other factors. We can make a more accurate prediction this way but the computation of the likelihood gets harder. We can make things easier by assuming that all the variables used to help our decision making are independent with each other. For example, we could assume here that the money taken from the fight and the opponent's record are independent, which is certainly not true in real life but the benefits of this assumption cannot be ignored. So let's see how this assumption leads to the Naive Bayes Classifier. Instead of reaching equation (6) we can do the following (using the definition of conditional probability):    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility|money,record) \\geq P(low\\,utility|money,record) \\implies $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{P(money,record,high\\,utility)}{P(money,record)} \\geq \\frac{P(money,record,low\\,utility)}{P(money,record)} \\implies $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money,record,high\\,utility) \\geq P(money,record,low\\,utility)\\tag{7}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A naive assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes assumption can be expressed mathematically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(B_1|B_2,\\dots,B_n,A)=P(B_1,A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind the assumption is the following. The knowledge of B2,...,Bn will not change how likely it is that the event B1 will happen. Only the information of the event A is useful. Using the definition of conditional probability and then applying the assumption to the left part of the inequality (7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money,record,high\\,utility)=P(money|record,high\\,utility)P(record,high\\,utility)=$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money|record,high\\,utility)P(record|high\\,utility)P(high\\,utility)=$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money|high\\,utility)P(record|high\\,utility)P(high\\,utility) \\tag{8}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can do the same thing for the right part of inequality (7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money,record,low\\,utility)=P(money|low\\,utility)P(record|low\\,utility)P(low\\,utility) \\tag{9}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plug the results of (8) and (9) back in (7) and we have the Naive Bayes decision criterion for our problem. The only thing left is to compute the quantities of eq. (8) and (9) and that's it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The purpose of this application is to demonstrate the classification task using the Naive Bayes Classifier without getting in too much detail. In another tutorial we will go through the process more thoroughly using Python. Consider the following dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/nikosga/Tutorials/master/pics/TABLE1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first column contains the utility experienced, the second contains the money earned and the third column contains the record of the opponent for each fight (values range from 0-100 where 0:never won and 100:never lost). In the yellow box we have the mean and standard deviation of the generated data. We will train the Naive Bayes using the above dataset and then we will use that model to make some predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Calculate the sample mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to calculate the sample mean and variance (or standard deviation, the squared root of variance) for the two classes using the formulas bellow: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mu = \\frac{\\displaystyle\\sum_{i=1}^{n}x_i} {n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next table we have the sample mean and standard deviation values for the two variables conditionally on the high/low utility classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/nikosga/Tutorials/master/pics/TABLE2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average money earned from fights that offered high utility is 7140 while for the low utility fights 4120. Observe that since our sample is pretty small, the law of large numbers has small effect and the mean/standard deviation estimates are far from the true values. Also the money and record variables are continuous so we will make the assumption that they are distributed normally given the knowledge we have on the class. For example the conditional probability of money can be expressed: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money|high\\,utility) = \\frac{1}{\\sqrt {2\\pi \\sigma_{high\\,utility}^2 } }exp\\left(-\\frac{(x_i-\\mu_{high\\,utility})^2}{2\\sigma_{high\\,utility}^2}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained the model. What's left is to compute the two posteriors for a new observation. So, assume that there is a new fight proposal. The compensation is 10000 and the opponent's record is 89. Whould you choose to fight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability that you will enjoy the fight given that you already know the money you will take and the level of the opponent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility|money,record)=\\frac{P(money|high\\,utility)P(record|high\\,utility)P(high\\,utility)}{P(money,record)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**What is the probability that you will NOT enjoy the fight given that you already know the money you will take and the level of the opponent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(low\\,utility|money,record)=\\frac{P(money|low\\,utility)P(record|low\\,utility)P(low\\,utility)}{P(money,record)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we mentioned in the theoretic part of this tutorial, the denominators are equal and we will just compare the numerators. So let's do it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High utility posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money=10000|high\\,utility)=\\frac{1}{\\sqrt {2\\pi 1460^2 } }exp\\left(-\\frac{(10000-7140)^2}{2\\times1460^2}\\right)=0.00004$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(record=89|high\\,utility)=\\frac{1}{\\sqrt {2\\pi 6.87^2 } }exp\\left(-\\frac{(89-77.8)^2}{2\\times6.87^2}\\right)=0.01537$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility)=P(low\\,utility)=0.5 \\implies \\frac{P(high\\,utility)}{P(money,record)}=\\frac{P(low\\,utility)}{P(money,record)}=const.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the first posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(high\\,utility|money,record)=0.00004\\times0.01537\\times const.=0.00000062\\times const.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low utility posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(money=10000|low\\,utility)=\\frac{1}{\\sqrt {2\\pi 1170^2 } }exp\\left(-\\frac{(10000-4120)^2}{2\\times1170^2}\\right)=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(record=89|low\\,utility)=\\frac{1}{\\sqrt {2\\pi 4.93^2 } }exp\\left(-\\frac{(89-45.4)^2}{2\\times4.93^2}\\right)=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low utility posterior is zero and thus  **the chances that you will enjoy the match are higher!**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is really important is how the posterior information helps our decision making. Without the additional information of money and opponent record we would be equally willing to choose to fight or not to, since the prior probabilities were equal. When we are provided with a new observation we find the probality that each feature realizes some value given its class. In the next plot we have a visual of the conditional probability of money for the two utility classes   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/nikosga/Tutorials/master/pics/multiple-sample-proportion-distribution2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chances that the 10000 payment will result in a good fight are small while there is now way this fight will end up being a bad experience. Finally, consider the following proposal: *\"If the money offered were 100000 then the probability of having a good fight would be zero too!\"* Remeber...we are calculating probabilities, not outputs of some utility function that proposes the more money the better. The reason that the probability of having a good fight if the payment is more than ten times the usual good-fight-payment is because you (the boxer) have never taken such a high payment in the past. Still it will be farther from zero than the probability of a bad fight and you will choose to fight again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "## Tutorial by _Nikos Gavriil_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
